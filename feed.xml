<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://talsperre.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://talsperre.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-02T07:59:23+00:00</updated><id>https://talsperre.github.io/feed.xml</id><title type="html">blank</title><subtitle>Shashank&apos;s personal website and blog. </subtitle><entry><title type="html">LLMs, Game Theory, and Market Dynamics</title><link href="https://talsperre.github.io/blog/2025/game-theory/" rel="alternate" type="text/html" title="LLMs, Game Theory, and Market Dynamics"/><published>2025-02-16T09:00:00+00:00</published><updated>2025-02-16T09:00:00+00:00</updated><id>https://talsperre.github.io/blog/2025/game-theory</id><content type="html" xml:base="https://talsperre.github.io/blog/2025/game-theory/"><![CDATA[<h2 id="grok-3-and-other-llm-announcements"><strong>Grok 3 and other LLM announcements</strong></h2> <p>This week, Elon Musk announced that Grok 3 is going to be released on February 17th, 2025. One reason to keenly watch the Grok 3 launch is that it‚Äôs one of the first models that has been trained on orders of magnitude more compute than previous gen GPT-4 class models. Grok 3 was pre-trained on the <a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/elon-musk-confirms-that-grok-3-is-coming-soon-pretraining-took-10x-more-compute-power-than-grok-2-on-100-000-nvidia-h100-gpus">Colossus supercluster</a>, which contains over 100,000 NVIDIA H100 GPUs. The success of Grok 3 and its performance on benchmarks will be a good indicator of whether the scaling laws surrounding pre-training of LLMs still hold. Grok 3‚Äôs release announcement has triggered a cascade of announcements across the LLM landscape. OpenAI announced that they will be launching GPT-4.5, codenamed Orion in a few weeks time, and <a href="https://arstechnica.com/ai/2025/02/sam-altman-lays-out-roadmap-for-openais-long-awaited-gpt-5-model/">GPT-5</a> a few months after that. Additionally, there‚Äôs <a href="https://techcrunch.com/2025/02/13/anthropics-next-major-ai-model-could-arrive-within-weeks/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAA7gdeeXoLhVq6eKujg65469N-Ep5I6Ul85jxeQneLRvQYJ30ivnje6AA0spHhCkSrfWmL3vn1iTwk-_If0xRPQyDL0lSMxB2cfbRhm8VPaSERmB1EB8qvF600GeXyRCyuAU27bxTmX-oY8IqsVbpcSxYfEZe09bacS8S3slhvnc">rumors</a> that Anthropic is also planning on releasing a new model right around the same timeline.</p> <div class="row justify-content-center"> <div class="col-md-4"> <div class="row mb-4"> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Grok 3 release with live demo on Monday night at 8pm PT. <br/><br/>Smartest AI on Earth.</p>&mdash; Elon Musk (@elonmusk) <a href="https://twitter.com/elonmusk/status/1890958798841389499?ref_src=twsrc%5Etfw">February 16, 2025</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </div> <div class="row mb-3"> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">OPENAI ROADMAP UPDATE FOR GPT-4.5 and GPT-5:<br/><br/>We want to do a better job of sharing our intended roadmap, and a much better job simplifying our product offerings.<br/><br/>We want AI to ‚Äújust work‚Äù for you; we realize how complicated our model and product offerings have gotten.<br/><br/>We hate‚Ä¶</p>&mdash; Sam Altman (@sama) <a href="https://twitter.com/sama/status/1889755723078443244?ref_src=twsrc%5Etfw">February 12, 2025</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </div> </div> <div class="col-md-6"> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Anthropic is shaking things up in the AI race! üöÄ Their new hybrid model offers a unique approach to reasoning, giving developers granular control over cost and speed. Will this be a game-changer? ü§î <br/><br/>Read our story: <a href="https://t.co/jBQslxiT16">https://t.co/jBQslxiT16</a><a href="https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw">#AI</a> <a href="https://twitter.com/hashtag/ArtificialIntelligence?src=hash&amp;ref_src=twsrc%5Etfw">#ArtificialIntelligence</a>‚Ä¶</p>&mdash; The Information (@theinformation) <a href="https://twitter.com/theinformation/status/1890484912748204381?ref_src=twsrc%5Etfw">February 14, 2025</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </div> </div> <p>This is a drastic departure from the past two years, where we saw a lot of announcement of new models, but not many releases that represented a step change in capabilities. <a href="https://openai.com/index/gpt-4-research/">GPT-4</a> was launched in May 2023, and the only other major update from OpenAI was the launch of <a href="https://openai.com/index/hello-gpt-4o/">GPT-4o</a> in May 2024, and the launch of reasoning models like <a href="https://openai.com/index/introducing-openai-o1-preview/">o1</a>, and <a href="https://openai.com/index/openai-o3-mini/">o3</a>. Unlike the jump in capabilities from GPT-3.5 to GPT-4, the jump in model quality from GPT-4 to GPT-4o was relatively minor. The same applies to the other capability jumps like those seen in the jump from <a href="https://www.anthropic.com/news/claude-3-family">Claude Sonnet</a> to <a href="https://www.anthropic.com/claude/sonnet">Claude Sonnet 3.5</a>, and from Gemini 1.5 Pro to Gemini 2.0 Pro. Reasoning models like o1 and o3 did show significant improvements in benchmark performance, but they are not directly comparable to base LLMs like GPT-4 since they rely on inference time compute.</p> <blockquote> <p>Grok 3 was announced finally on 17th February 2025 and it is indeed a great model. The model is first on <a href="https://x.com/lmarena_ai/status/1891706264800936307">LMArena leaderboard</a> with a score of over <code class="language-plaintext highlighter-rouge">1400</code> and its performance on <a href="https://x.com/emollick/status/1891708599560253906">benchmarks</a> is comparable to OpenAI‚Äôs <code class="language-plaintext highlighter-rouge">o3</code> models. The scale of improvements is not as drastic as the jump from GPT-3 to GPT-4, but the time it took xAI to catch up with other labs is impressive.</p> </blockquote> <h3 id="why-the-rush-to-release-models-now">Why the rush to release models now?</h3> <p>What‚Äôs interesting is that all of these companies plan on releasing their new LLMs within a few weeks of each other. Training these models often takes several months, and the post-training, fine-tuning, and red-teaming adds a few more months to this process. Given the long lead times, it‚Äôs unlikely that all of these companies just happened to finish training their models at the same time. This in turn, suggests that most of these companies have been sitting on their best models for a while, and are only releasing them now due to competitive pressures.</p> <p>But why would they do this? In a highly competitive market, it makes total sense for companies to release their best models as soon as they are ready, capture as much market share as possible, and then iterate on the next version. This has been the oft-repeated strategy in the tech industry in the past, and was taken to its zenith by companies like Uber, and Airbnb. The typical playbook during the Zero Interest Rate Policy (ZIRP) era was to raise massive amounts of capital, utilize that capital to subsidize services, and capture as much market share as possible. To hone in on the point further:</p> <ul> <li>Uber first launched a beta/demo in San Francisco in 2010.</li> <li>By 2012, Uber was serving rides across the US and in multiple cities across Europe.</li> <li>By 2013, Uber was available in <a href="https://www.theguardian.com/news/2022/jul/15/embrace-the-chaos-a-history-of-ubers-rapid-expansion-and-fall-from-favour">74</a> cities and was valued at $3.5 billion.</li> </ul> <p>This paradigm of flooding the market with your best product using VC funding as soon it is ready doesn‚Äôt seem to apply to the LLM space. This is due to a unique set of circumstances and market circumstances like:</p> <ul> <li>High interest rates</li> <li>Competitive dynamics among companies due to the existence of knowledge distillation,</li> <li>And the possibility of recursive self-improvement of models which depend on acquiring more user data and training even larger models.</li> </ul> <p>Let‚Äôs explore each one of these in more detail.</p> <h2 id="high-interest-rates">High Interest Rates</h2> <p>During the ZIRP era, raising capital was easy - this capital could be deployed quickly to build out infrastructure, acquire users, and capture market share. However, the higher interest rates of the past few years have made it difficult to apply the same playbook. The foundational assumption of the earlier tech era companies was that the initial infrastructure, R&amp;D, and user acquisition costs would be high, but once a user was acquired, the marginal cost of serving that user would be low. This is what makes Google‚Äôs AdWords, Facebook‚Äôs marketplace / Ad network, and AWS‚Äôs compute services so profitable. However, the marginal cost of serving users in the LLM space is not low, and is estimated to be in multiple billions of dollars. Tn fact, the marginal cost of serving a user is significantly higher for models using inference time compute like <code class="language-plaintext highlighter-rouge">o1</code>, <code class="language-plaintext highlighter-rouge">o1 pro</code>, and <code class="language-plaintext highlighter-rouge">o3</code>, and is requiring companies to spend massively on data center and power generation. The costs are so high that OpenAI has to charge over $200 for their most premium <a href="https://openai.com/chatgpt/pricing/">subscription</a> which is the only way to access their latest o1 pro models.</p> <p>The return to a world where marginal costs matter once more implies that companies like OpenAI, Anthropic, Google, and others have to be more judicious in how they deploy their capital, and make sure that they are able to recoup their costs.</p> <h2 id="competitive-market-dynamics">Competitive market dynamics</h2> <p>Beyond the financial constraints, two key competitive dynamics define how companies navigate the LLM landscape:</p> <ul> <li>User acquisition and training data acquisition</li> <li>Knowledge distillation</li> </ul> <p>Both these dynamics are interrelated, and result in a game theoretic situation where entities are incentivized to act in a certain way depending on what they think other entities will do, and the other entities‚Äô actions.</p> <h3 id="user-acquisition-and-training-data-acquisition">User Acquisition and Training Data Acquisition</h3> <p>LLMs are trained on vast amounts of data, and if the <a href="https://arxiv.org/abs/2203.15556">scaling laws</a> hold, then training larger models on more data will result in better models. This implies that the entity that acquires the most users, and subsequently the most data, will be able to train the best models, all other things being equal. Thus, entities are incentivized to acquire as many users as possible, which can be done by either releasing new state-of-the-art models that are significantly better than the competition, or by offering the best models at a lower price point.</p> <h3 id="knowledge-distillation">Knowledge Distillation</h3> <p>On the one hand, releasing new frontier models has positive network effects for the entity releasing the model, its benefits are short-lived. This is due to the existence of <strong>Knowledge Distillation</strong>, which allows other entities to train smaller models that have similar performance to the original entity‚Äôs frontier model at a fraction of the cost. Distillation is very common in the LLM space and is frequently used by companies to train smaller models that can serve users at a lower price point. Some examples of this include DeepSeek‚Äôs V3 model, LLama 7B model, OpenAI‚Äôs GPT-4o mini, and Google‚Äôs Gemini 2.0 Flash.</p> <h4 id="what-is-knowledge-distillation">What is Knowledge Distillation?</h4> <p><strong>Knowledge Distillation</strong> was first proposed in its modern form by Geoffrey Hinton, Oriol Vinyals, and Jeff Dean in their 2015 paper <a href="https://arxiv.org/abs/1503.02531">Distilling the Knowledge in a Neural Network</a>. It‚Äôs a fairly old concept, at least by modern ML standards, and at its core, is just a process of training a smaller model to mimic the behavior of a larger model. While a fairly simple concept, the implications of knowledge distillation being possible are profound. Here‚Äôs another way of looking at knowledge distillation:</p> <ul> <li>Say, you have a large model \(X\) trained on a dataset \(D\), with a certain performance metric \(Y\).</li> <li>Now, you want to train a much smaller model \(X'\) with smaller compute budget that has roughly similar performance to \(X\).</li> <li>Instead of training \(X'\) on \(D\) directly, you instead train it on the predictions of \(X\) on \(D\).</li> <li>This surprisingly results in better performance than training \(X'\) on \(D\) directly.</li> </ul> <p>Here‚Äôs a more authoritative excerpt from a 2021 paper ‚ÄúDoes Knowledge Distillation Really Work?‚Äù by <a href="https://arxiv.org/abs/2106.05237">Stich et al.</a>:</p> <blockquote> <p>Large, deep networks can learn representations that generalize well. While smaller, more efficient networks lack the inductive biases to find these representations from training data alone, they may have the capacity to represent these solutions. Influential work on knowledge distillation argues that Bucila et al. ‚Äúdemonstrate convincingly that the knowledge acquired by a large ensemble of models <strong>[the teacher]</strong> can be transferred to a single small model <strong>[the student]</strong>‚Äù. Indeed this quote encapsulates the conventional narrative of knowledge distillation: a student model learns a high-fidelity representation of a larger teacher, enabled by the teacher‚Äôs soft labels.</p> </blockquote> <p>Several mechanisms for knowledge distillation have been proposed in literature such as using a distillation loss to capture the difference between the teacher and student predictions, using novel architectures and distillation loss functions that minimize the difference between the feature activations of the teacher and student, and more. Knowledge Distillation itself can be applied at various stages of model training:</p> <ul> <li>In an offline setting, where the teacher model is trained first, and then the student model is trained on the teacher‚Äôs predictions.</li> <li>In an online setting, where the teacher and student models are trained simultaneously in an end-to-end manner.</li> <li>Self-distillation, where the teacher and student models are the same, and the deeper layers of the model are used to train the shallower layers.</li> </ul> <p>This <a href="https://neptune.ai/blog/knowledge-distillation">blog post</a> goes into greater detail on the various types of knowledge distillation, and specific case studies.</p> <h4 id="why-does-knowledge-distillation-matter">Why does knowledge distillation matter?</h4> <p>As explained earlier, the entity releasing the best model first only has a short window of time to reap the economic rewards from it, before others distill from it and release smaller models that have similar performance. The plot below shows how the compute budget required to train a new non-reasoning frontier LLM has been increasing exponentially over the past few years. The compute budget for Grok 3 pre-training is estimated to be around \(10\times\) that of GPT-4, and that of GPT-4 itself was rouhgly \(50\times\) that of GPT-3. However, once a new frontier LLM is released, it only takes roughly a year at max for other companies to release much smaller models that have similar performance to the previous frontier LLM.</p> <div class="l-page"> <iframe src="/assets/d3/post2/llm_scaling.html" width="100%" height="720px" style="border: 1px dashed grey; overflow: hidden;"> </iframe> </div> <p>For instance, DeepSeek‚Äôs V3 model, a highly capable GPT-4 level model, was trained on just a cluster of 2048 H800 GPUs, which is a fraction of the GPUs used to train GPT-4. To achieve this drastic reduction in compute costs, DeepSeek made several innovations such as:</p> <ul> <li>Leveraging Nvidia‚Äôs assembly level PTX programming directly to bypass the limitations of the CUDA API, making it easier to achieve better GPU interconnect bandwidth.</li> <li>Using a novel multi-head latent attention layer that uses low rank compression of keys and values, to reduce memory footprint.</li> <li>Using DeepSeekMoE with support for hybrid routing, dynamic load balancing, and sequence wise balancing, to improve the efficiency of the model.</li> </ul> <p>However, DeepSeek‚Äôs V3 model also benefited from the fact that it was able to distill from other frontier LLMs like OpenAI‚Äôs GPT-4o, if OpenAI‚Äôs / Microsoft‚Äôs <a href="https://www.theverge.com/news/601195/openai-evidence-deepseek-distillation-ai-data">claims</a> are to be believed. Thus, there is a game theory dynamic at play where entities are incentivized to sit on their best models until the last possible moment, and only release them when forced by market conditions.</p> <h2 id="recursive-self-improvement">Recursive self-improvement</h2> <p>I personally don‚Äôt ascribe to the view that LLMs will achieve recursive self-improvement anytime soon, but it‚Äôs worth mentioning as another factor that could be driving the strategy of releasing frontier models amongst entities. The idea of recursive self-improvement is that once an AI system reaches a certain threshold of capability, it can then use that capability to improve itself further, and so on. Think of it as a positive feedback loop where the AI uses its current capabilities to improve itself exponentially, resulting in an Artificial Superintelligence (ASI). For entities ascribing to this view, there is no incentive to release new frontier models unless it is already an ASI due to two reasons:</p> <ul> <li>Every small improvement in the model‚Äôs current capabilities could be used to improve the model further, and releasing it to the public would allow other‚Äôs to reverse engineer the improvements or distill from it. In order to truly reap the economic rewards of recursive self-improvement, it only makes sense to release the model once it is already an ASI.</li> <li>For entities concerned about ‚ÄúAI safety‚Äù or ‚ÄúAI alignment‚Äù, releasing a model that is capable of recursive self-improvement could be catastrophic if the model is not aligned with human values. Thus, they would rather release models only after they have ensured that the model is aligned with human values, and is safe to use.</li> </ul> <p>These values seem to align with strategies of companies like <a href="https://ssi.inc/">Safe Superintelligency (SSI)</a>, and <a href="https://www.anthropic.com/">Anthropic</a>,</p> <h2 id="how-is-this-related-to-game-theory"><strong>How is this related to game theory?</strong></h2> <p>The competing dynamics of user/data acquisition, knowledge distillation, and recursive self-improvement can be modelled using game theory. There are several competitors, which have partial information about each other‚Äôs capabilities, and are incentivized to act in a way that maximizes their own utility, but not necessarily the utility of the group. The utility for various entities is different, but at a high level, it can be thought of as maximizing shareholder value. There are several other factors at play as well, some of which can be confounding, such as regulatory constraints, ethical considerations, and more. Thus, any attempt to model this using a simple game theoretic framework would be an oversimplification, but it‚Äôs still a good approximation of the competitive dynamics at play - and can be used to answer the original question of why release of frontier models are typically clustered together.</p> <h3 id="modeling-the-llm-space-as-a-two-stage-coordination-game">Modeling the LLM space as a two-stage coordination game</h3> <p>The forces of user/data acquisition and knowledge distillation are at odds with each other, and can be modeled as a two-stage coordination game. Both stages can be modelled as a coordination game, but the strategies and payoffs are different for each stage.</p> <h4 id="what-is-a-coordination-game">What is a coordination game?</h4> <p>A <a href="https://en.wikipedia.org/wiki/Coordination_game">Coordination game</a> is a type of game where players benefit from making the same or compatible choices. Assuming rationality, the key characteristic of coordination games is that there are multiple equilibrium, and the main challenge lies in selecting the equilibrium that is most beneficial for all players. Selecting the optimal equilibrium is often difficult due to the lack of communication between players, or having only partial information about the other players‚Äô strategies. A <a href="https://en.wikipedia.org/wiki/Focal_point_(game_theory)">Schelling point</a> (or focal point) is a solution that players tend to choose in the absence of communication because it appears naturally prominent or intuitive. Depending on the payoffs, the Schelling point is often the optimal equilibrium for all players, but in other cases, it might be worse for all entities involved.</p> <p>The competitive dynamics in the LLM space can be modeled as a coordination game because all entities can be assumed to be rational, and act in their own self-interest, and only have partial information about the other‚Äôs entities strategies. In other words, in the absence of direct communication, the entities will have to make decisions based on their own self-interest, and also based on an understanding of what the other entities are likely to do.</p> <h4 id="stag-hunt-and-prisoners-dilemma-games">Stag Hunt and Prisoner‚Äôs Dilemma games</h4> <p>More concretely, the competitive dynamics can be modeled as a two-stage coordination game, where the first stage is a ‚ÄúStag Hunt‚Äù game, and the second stage is a ‚ÄúPrisoner‚Äôs Dilemma‚Äù game. The videos below provide a good overview of the <a href="https://en.wikipedia.org/wiki/Stag_hunt">Stag Hunt</a> and <a href="https://en.wikipedia.org/wiki/Prisoner%27s_dilemma">Prisoner‚Äôs Dilemma</a> games, and how the payoffs are different for each game. The difference in payoffs between the two games also results in a difference in strategies that players are incentivized to take to maximize their utility.</p> <div class="row justify-content-center w-100"> <div class="col-sm-6"> <iframe width="100%" height="400" src="https://www.youtube.com/embed/oQ3KmcjwuKU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" style="border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);"> </iframe> </div> <div class="col-sm-6"> <iframe width="100%" height="400" src="https://www.youtube.com/embed/jr2b0aZfOZQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" style="border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);"> </iframe> </div> </div> <blockquote> <p>Videos were created by the <code class="language-plaintext highlighter-rouge">o1</code> model using <a href="https://www.manim.community/">manim</a> and the prompts were created by yours truly.</p> </blockquote> <p>In the context of frontier LLM releases, the first stage can be represented as a <strong>Stag Hunt</strong> game, where entities are incentivized to hold out on releasing their best models for as long as market conditions allow. Sitting on the best model allows entities to capture as much value out of their existing models and infrastructure as possible, and also provides enough time to train the next frontier model. Releasing a new model does provide a guaranteed short-term competitive advantage over other entities, but in the long run, the benefits are not as clear, since it won‚Äôt take long for other entities to catch up via distillation or other means. There are two equilibriums possible in this stage:</p> <ul> <li><strong>Equilibrium 1</strong>: All entities hold out on releasing their best models, and only release them when forced by market conditions.</li> <li><strong>Equilibrium 2</strong>: One entity releases their best model, and forces all other entities to release their best models as well. This implies that all entities release their best models at the same time.</li> </ul> <div class="row justify-content-center"> <div class="col-sm-8"> <iframe width="100%" height="500" src="/assets/d3/post2/stag_hunt_payoff_matrix.html" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" style="border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);"> </iframe> </div> </div> <p>The payoff matrix for the Stag Hunt game in the LLM space is shown above. Due to the existence of partial communication among the various entities, and partial trust in the other entities‚Äô strategies, the Schelling point in this case is to hold out on releasing the best model, and it also happens to be the optimal equilibrium for all entities involved. This is exactly what we are witnessing in the last few months. However, as soon as one entity releases or announces a plan to release a new frontier model, the market dynamics change, and the second stage of the game begins.</p> <p>The second stage of the game has different payoff structure, and can be modelled as a <strong>Prisoner‚Äôs Dilemma</strong> game. In this game, entities are forced to release their best models to prevent other entities from capturing market share at their expense. Given the nature of the payoffs, there is only one equilibrium in this game:</p> <ul> <li><strong>Equilibrium 1</strong>: All entities are forced to release their best models as soon as one entity announces a plan to release a new frontier model.</li> </ul> <p>Unlike the Stag Hunt game, there is only one Nash equilibrium in the Prisoner‚Äôs Dilemma which is <code class="language-plaintext highlighter-rouge">(Defect, Defect)</code> (or <code class="language-plaintext highlighter-rouge">(Release, Release)</code> to be more specific). Defection is the dominant strategy in this game, and since all entities are aware of this, the Schelling point also becomes <code class="language-plaintext highlighter-rouge">(Defect, Defect)</code>. However, unlike the Stag Hunt game, the Schelling point is not the pareto optimal and is not the best outcome for all entities involved. Taken to its extreme, this bodes poorly for the frontier LLM providers, as they will have to constantly raise new capital to expand their infrastructure, and train even larger models to stay ahead of the competition. Additionally, there are other entities which aren‚Äôt interested in developing frontier LLMs, but nonetheless benefit from the existence of these models due to knowledge distillation. In an ideal world, all entities would be better off if they held out on releasing their best models, but the payoffs are such that the dominant strategy is worse for all entities involved. The payoff matrix for the Prisoner‚Äôs Dilemma game in the LLM space is shown below.</p> <div class="row justify-content-center"> <div class="col-sm-8"> <iframe width="100%" height="500" src="/assets/d3/post2/prisoners_dilemma_payoff_matrix.html" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" style="border-radius: 8px; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);"> </iframe> </div> </div> <p>We have seen dynamic play out just a month ago, when OpenAI made <a href="https://openai.com/index/openai-o3-mini/">o3 mini</a> available for free to all users, as soon as DeepSeek announced their R1 model. We are seeing the same dynamic play out again, with OpenAI and Anthropic have announced their intent to release new frontier models in the coming weeks, due to Grok 3‚Äôs imminent release. The visualization‚Äôs below show how the payoffs and the dominant strategies change between the two stages of the game.</p> <h2 id="implications"><strong>Implications</strong></h2> <p>The above game theoretic model provides a good approximation of the competitive landscape in the LLM space, but is not a perfect model. It suffers from some drawbacks, chiefly:</p> <ul> <li>While most entities can be assumed to be rational and act in their own self-interest, i.e. maximize shareholder value, the means to achieve this may vary. For instance, companies like Meta and Amazon benefit from LLMs becoming commoditized since they are aggregators, and can thus release new models as soon as they are ready.</li> <li>If releasing frontier models is indeed the dominant strategy, then this might result in an arms race, where entities are incentivized to constantly train larger models to stay ahead of the competition. However, this means less time and resources are spent on important safety aspects like model alignment, and ethical considerations. <strong>Note</strong>: This is a highly controversial topic, and I am not suggesting that safety either be prioritized or deprioritized, but it‚Äôs a tradeoff that entities will have to make.</li> <li>Releasing becoming the dominant strategy implies that frontier LLMs will become commoditized. This means that the economic rewards from releasing new models not only accrue to other competitors, but also to entities in other industries that can leverage these models to improve their own workflows. Thus, there is an argument to be made that policies should incentivize entities to release frontier models as soon as they are ready, for the ‚Äúgreater good‚Äù.</li> </ul>]]></content><author><name></name></author><category term="tech"/><category term="llms"/><category term="ai"/><category term="tech"/><summary type="html"><![CDATA[Game theory of frontier LLMs]]></summary></entry><entry><title type="html">OpenAI Native Image Generation - Generative Reality, Generative UI, and more</title><link href="https://talsperre.github.io/blog/2025/generated-reality/" rel="alternate" type="text/html" title="OpenAI Native Image Generation - Generative Reality, Generative UI, and more"/><published>2025-02-16T09:00:00+00:00</published><updated>2025-02-16T09:00:00+00:00</updated><id>https://talsperre.github.io/blog/2025/generated-reality</id><content type="html" xml:base="https://talsperre.github.io/blog/2025/generated-reality/"><![CDATA[<p>A short post on native image generation in LLMs, OpenAI‚Äôs GPT-4o release and Studio Ghibli trend, and applications of native image generation like ‚ÄúGenerative UI‚Äù and ‚ÄúGenerative Reality‚Äù.</p> <h2 id="openai-native-image-generation"><strong>OpenAI Native Image Generation</strong></h2> <p>OpenAI <a href="https://openai.com/index/introducing-4o-image-generation/">announced</a> native image generation in <code class="language-plaintext highlighter-rouge">GPT-4o</code> on March 25th, 2025. Immediately after the announcement, Machine Learning <a href="https://grok.com/share/bGVnYWN5_9177404c-2e12-4246-abc4-5b422ec48a9a">TPOT</a> (This Part of Twitter) was flooded with tweets the model‚Äôs ability to generate a version of the provided image in the style of <a href="https://en.wikipedia.org/wiki/Studio_Ghibli">Studio Ghibli</a>, an animation style initially popularized by Hayao Miyazaki and Isao Takahata. The ‚Äúoffending‚Äù tweet by <a href="https://x.com/GrantSlatton/status/1904631016356274286"><code class="language-plaintext highlighter-rouge">@GrantSlatton</code></a> is provided below (left). People were quick to jump on the bandwagon, with users posting ‚ÄúGhiblifying‚Äù images of their friends, families, and iconic pictures from both pop/meme culture.</p> <div class="container"> <div class="row justify-content-center"> <div class="col-md-6"> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">tremendous alpha right now in sending your wife photos of yall converted to studio ghibli anime <a href="https://t.co/FROszdFSfN">pic.twitter.com/FROszdFSfN</a></p>&mdash; Grant Slatton (@GrantSlatton) <a href="https://twitter.com/GrantSlatton/status/1904631016356274286?ref_src=twsrc%5Etfw">March 25, 2025</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </div> <div class="col-md-6"> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Iconic movie scenes, Studio Ghibli style. This is so much fun! <a href="https://t.co/LwjkNjcEV9">pic.twitter.com/LwjkNjcEV9</a></p>&mdash; Mufaddal Durbar (@MDurbar) <a href="https://twitter.com/MDurbar/status/1904872441899339963?ref_src=twsrc%5Etfw">March 26, 2025</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </div> </div> </div> <p>Even though, generating ghiblified versions of images is fun, these native image generation models are capable of much more than that. They can potentially remove watermarks from images, add/remove subjects from images, help with interior design and more. What‚Äôs interesting is that despite all the hype about AI art and AI generated images, the most popular use case right now seems to be modifying existing images of friends, family, and pets in various styles. Imitation is the sincerest form of flattery, and the fact that people are using these models to add filters on top of their own photos is extremely revealing of two things:</p> <ul> <li>True creativity is still exceptionally rare and very valuable,</li> <li>Providing some notion of control over the output space rather than a blank canvas is more appealing to the average user.</li> </ul> <p><em>This newfound capability raises a natural question: what exactly is native image generation, and how does it differ from earlier approaches? Let‚Äôs dive into the technical details.</em></p> <h3 id="what-is-native-image-generation">What is Native Image Generation?</h3> <p>Earlier image generation models like <code class="language-plaintext highlighter-rouge">DALL-E</code>, <code class="language-plaintext highlighter-rouge">CLIP</code>, <code class="language-plaintext highlighter-rouge">Imagen</code>, and more relied on diffusion models, Vision Transformers, or Generative Adversarial Networks (does anyone still remember GANs?). In contrast, newer models like <code class="language-plaintext highlighter-rouge">GPT-4o</code>, <code class="language-plaintext highlighter-rouge">Grok 3</code>, and <code class="language-plaintext highlighter-rouge">gemini-2.0-flash-exp-image-generation</code> (yes, that‚Äôs really the name ü§¶‚ÄçÔ∏è) are truly multimodal. These models can generate images and audio in an autoregressive manner, much like they generate text. The GIF below illustrates how autoregressive text generation works in an earlier model like <code class="language-plaintext highlighter-rouge">GPT-2</code>. Autoregressive in the context of an LLM means that in order to generate the next token, the model conditions its prediction on the provided context (prompt and system prompt) and the previously generated tokens. For instance if the system prompt is ‚ÄúAnswer the users question in a single sentence‚Äù and the prompt is ‚ÄúRecite the first law of robotics‚Äù, the following steps are taken:</p> <ul> <li>The model (GPT-2) encodes the system prompt and the user prompt and updates the state of the Key, Query, and Value vectors (attention mechanism) in the transformer model.</li> <li>The model generates the first token <code class="language-plaintext highlighter-rouge">"A"</code> based on this internal state.</li> <li>The model modifies the internal state with the output <code class="language-plaintext highlighter-rouge">"A"</code> and then uses this modified state to predict the next token <code class="language-plaintext highlighter-rouge">"robot"</code>.</li> <li>The model continues this process until the end of the sequence is reached, which is either a maximum length or a special token like <code class="language-plaintext highlighter-rouge">&lt;|endoftext|&gt;</code>.</li> </ul> <p>As the other image on the right shows, multimodal models like <code class="language-plaintext highlighter-rouge">GPT-4o</code> treat text, image pixels, and audio waveforms as different tokens, and jointly train across all three modalities. During generation, predict a pixel, a word, or a waveform at a time. In a very naive sense, the model can be thought of as generating pixels from left-to-right, and top-to-bottom.</p> <div class="row justify-content-center w-100"> <div class="col-md-8"> <figure class="figure"> <img src="/assets/img/post3/gpt-2-autoregression-2.gif" alt="Autoregressive generation" class="img-fluid rounded z-depth-1" onclick="this.classList.toggle('zoomed')"/> <figcaption class="figure-caption text-center mt-2">Autoregressive text generation process in GPT-2 <a href="https://jalammar.github.io/illustrated-gpt2/">[*]</a></figcaption> </figure> </div> <div class="col-md-4"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/multimodal-llms-480.webp 480w,/assets/img/post3/multimodal-llms-800.webp 800w,/assets/img/post3/multimodal-llms-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/multimodal-llms.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="figure-caption text-center mt-2">Multimodal Large Language Model architecture</figcaption> </div> </div> <p><br/></p> <p>The main advantage of this approach is efficiency: we no longer need specialized systems for different modalities, streamlining both training and inference. Additionally, these models leverage cross-modal relationships, enhancing their contextual understanding of scenes.</p> <h3 id="how-does-it-really-work">How Does It Really Work?</h3> <p>Multimodal LLMs fall into two main categories:</p> <ul> <li>Models that process multiple input modalities (e.g., images, audio, text) but only generate text as output, such as <a href="https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/">LLaMA 3.2</a>.</li> <li>Models that can also generate images or audio as output, like <code class="language-plaintext highlighter-rouge">GPT-4o</code> and <code class="language-plaintext highlighter-rouge">Grok 3</code>.</li> </ul> <h4 id="deeper-dive-into-multi-modal-models">Deeper dive into multi-modal models</h4> <div class="row justify-content-center w-100"> <div class="col-md-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/multimodal-llm-input-480.webp 480w,/assets/img/post3/multimodal-llm-input-800.webp 800w,/assets/img/post3/multimodal-llm-input-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/multimodal-llm-input.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="figure-caption text-center mt-2">Processing image using VIT for multi-modal LLMs <a href="https://sebastianraschka.com/blog/2024/understanding-multimodal-llms.html">[*] </a></figcaption> </div> </div> <p><br/></p> <p>The mechanism of processing multimodal inputs is roughly similar in both these types of models but the output generation is different. The image below shows how a multi-modal LLM can process an image as well as text together to generate a response.</p> <ul> <li>These multi-modal models typically process an image into a smaller chunks of size <code class="language-plaintext highlighter-rouge">16 x 16</code> or <code class="language-plaintext highlighter-rouge">32 x 32</code> pixels, in a left to right, top to bottom manner.</li> <li>These chunks are fed in a sequential manner to another model, typically a Vision Transformer (ViT), which processes these image chunks and generates a representation for each chunk. These intermediate representations are then fed into a linear projection layer, which resizes the image representations to the same dimensionality as the input text embeddings, and also ensures that the generated image embeddings are in the same ‚Äúlatent space‚Äù as the text embeddings.</li> <li>This alignment is done by training the model, specifically the projection layers on a large dataset of text-image pairs, after the base LLM has finished training.</li> </ul> <p>Models from different research groups use varying approaches for training, especially regarding which layers to freeze and which to update, but it common to only update the linear projection layer and image encoder during training. For instance, see this snippet from the LLama 3.2 blog post:</p> <blockquote> <p>To add image input support, we trained a set of adapter weights that integrate the pre-trained image encoder into the pre-trained language model. The adapter consists of a series of cross-attention layers that feed image encoder representations into the language model. We trained the adapter on text-image pairs to align the image representations with the language representations. During adapter training, we also updated the parameters of the image encoder, but intentionally did not update the language-model parameters. By doing that, we keep all the text-only capabilities intact, providing developers a drop-in replacement for Llama 3.1 models.</p> </blockquote> <p>This <a href="https://sebastianraschka.com/blog/2024/understanding-multimodal-llms.html">blog post</a> by Sebastian Raschka provides a more technical deep dive into how multi-modal models are trained, and the state-of-the-art models in this space as of late <code class="language-plaintext highlighter-rouge">2024</code>. However, the blog post does not cover the generation/decoding process for multimodal models like <code class="language-plaintext highlighter-rouge">GPT-4o</code> and <code class="language-plaintext highlighter-rouge">Grok 3</code>, which not only process multimodal inputs, but are also capable of generating images in an autoregressive manner. The concept of generating images in an autoregressive manner is not new, and has been explored as far back as the 2016s in papers like <a href="https://arxiv.org/abs/1601.06759">PixelRNN</a>. PixelRNN simply used an RNN to predict the next pixel in an image, given the previous pixels.</p> <p>However, there have been several improvements to such models in recent years, with most of the improvements coming in the way that</p> <ol> <li>Images are encoded (CLIP/VQ-VAE) and,</li> <li>Modifying the process of autoregressive generation itself from sequential visual token generation in a raster-scan order, to more complex generation processes like Visual AutoRegressive modeling (VAR), which is autoregressive generation of images as coarse-to-fine ‚Äúnext-scale prediction‚Äù or ‚Äúnext-resolution prediction‚Äù.</li> </ol> <p>Visual AutoRegressive modeling was introduced in the 2024 NeurIPS Best Paper award-winning paper <a href="https://arxiv.org/pdf/2404.02905">‚ÄúVisual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction‚Äù</a>.</p> <ul> <li>The model first generates a low-resolution image starting from a \(1 \times 1\) token map, and then progressively increases the resolution by making the transformer based model to predict the higher resolution map.</li> <li>Each higher resolution map is conditioned on the previous lower resolution map, thus making the generation process autoregressive.</li> <li>Importantly, the authors show empirical validation of te scaling laws and zero-shot generalization potential of the VAR model, which is markedly similar to those of other LLMs.</li> </ul> <div class="row justify-content-center w-100"> <div class="col-md-12"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/var-auto-regressive-models-480.webp 480w,/assets/img/post3/var-auto-regressive-models-800.webp 800w,/assets/img/post3/var-auto-regressive-models-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/var-auto-regressive-models.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="figure-caption text-center mt-2">A Visual AutoRegressive model generates images in a coarse-to-fine manner <a href="https://arxiv.org/pdf/2404.02905">[*]</a></figcaption> </div> </div> <p><br/></p> <p>The diagram above shows the process of VAR generation as described in the paper. This is not the only way to generate images in an autoregressive manner, and it isn‚Äôt clear if <code class="language-plaintext highlighter-rouge">GPT-4o</code> or other native image generation models like <code class="language-plaintext highlighter-rouge">Gemini 2.0 Pro Experimental</code> and <code class="language-plaintext highlighter-rouge">Grok 3</code> use similar techniques. There have been some speculations that the GPT-4o model performs autoregressive generation of images in a raster-scan order (left to right, top to bottom), with generation happening at all scales simultaneously. Another speculation is that there are two separate models, <code class="language-plaintext highlighter-rouge">GPT-4o</code> generates tokens in the image latent space, and a separate diffusion based decoder generates the actual image - see tweets below. Given the artifacts being generated in the ChatGPT UI like top-down generation, blurry intermediates, etc., I believe the latter speculation is more likely.</p> <div class="container"> <div class="row justify-content-center"> <div class="col-md-6"> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Okay my working hypothesis for 4o image generation is that it is jointly performing autoregressive inference (raster scanline order) on an image pyramid at all scales simultaneously. <a href="https://t.co/WMoidIuvN3">https://t.co/WMoidIuvN3</a></p>&mdash; Jon Barron (@jon_barron) <a href="https://twitter.com/jon_barron/status/1905143840572583974?ref_src=twsrc%5Etfw">March 27, 2025</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </div> <div class="col-md-6"> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">How would gpt-4o image generation work? Speculation:<br/><br/>- gpt-4o generates visual tokens, and the diffusion decoder decodes them to pixel space. <br/>- Not just diffusion but Rolling Diffusion-like group-wise diffusion decoder, top-&gt;bottom ordering. <a href="https://t.co/4uIv8m7aIq">pic.twitter.com/4uIv8m7aIq</a></p>&mdash; Sangyun Lee (@sang_yun_lee) <a href="https://twitter.com/sang_yun_lee/status/1905411685499691416?ref_src=twsrc%5Etfw">March 28, 2025</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </div> </div> </div> <h3 id="is-any-of-this-new"><strong>Is any of this new?</strong></h3> <p><strong>The resounding answer is no.</strong></p> <p>In fact, some of the style transfer results shown earlier are reminiscent of the results from <a href="https://en.wikipedia.org/wiki/DeepDream">DeepDream</a> and <a href="https://www.v7labs.com/blog/neural-style-transfer">Neural Style Transfer</a> work by Gatys et al. in their paper <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf">‚ÄúImage Style Transfer Using Convolutional Neural Networks‚Äù</a> in 2016. The main caveat being that the results weren‚Äôt as impressive, and they used completely different architectures and training methods to achieve the results. Several other models like Google‚Äôs Gemini are multi-modal as well and support similar image generation capabilities. <a href="https://x.com/OriolVinyalsML/status/1899853815056085062">Here‚Äôs</a> the Gemini announcement for instance:</p> <div class="container"> <div class="row justify-content-center"> <div class="row-md-4"> <div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Gemini 2.0 Flash debuts native image gen! Create contextually relevant images, edit conversationally, and generate long text in images. All totally optimized for chat iteration.<br/><br/>Try it in AI Studio or Gemini API. Blog: <a href="https://t.co/pkeRzaD8b5">https://t.co/pkeRzaD8b5</a> <a href="https://t.co/c7QUzNfC4k">pic.twitter.com/c7QUzNfC4k</a></p>&mdash; Oriol Vinyals (@OriolVinyalsML) <a href="https://twitter.com/OriolVinyalsML/status/1899853815056085062?ref_src=twsrc%5Etfw">March 12, 2025</a></blockquote> <script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> </div> </div> </div> </div> <p>However, none of them managed to capture the public imagination like this release from OpenAI. The main reason for the relative lack of fanfare regarding the <code class="language-plaintext highlighter-rouge">Gemini</code> announcement was two-fold:</p> <ul> <li>The <code class="language-plaintext highlighter-rouge">Gemini</code> releases were not product centric. The <code class="language-plaintext highlighter-rouge">Gemini</code> image generation model is only available as a preview model in Google AI Studio, and via <code class="language-plaintext highlighter-rouge">Gemini</code> API, and not in the main Gemini web interface. <code class="language-plaintext highlighter-rouge">GPT-4o</code>, on the other hand is available for users in the main ChatGPT website, immediately after the announcement. This is where network effects of over 400 million Weekly Active Users (WAUs) of ChatGPT come into play.</li> <li>The other harsh truth is that the image outputs of the <code class="language-plaintext highlighter-rouge">Gemini</code> model are simply not as good as the <code class="language-plaintext highlighter-rouge">GPT-4o</code> model. The results of both the Gemini model and the <code class="language-plaintext highlighter-rouge">GPT-4o</code> model on the same prompts are shown later <a href="#putting-openais-image-generation-to-the-test">here</a>.</li> </ul> <h3 id="putting-openais-image-generation-to-the-test">Putting OpenAI‚Äôs image generation to the test</h3> <div class="container"> <div class="row justify-content-center"> <div class="col-md-4"> <div style="position: relative;"> <img-comparison-slider hover="hover" value="70"> <figure slot="first"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-original-480.webp 480w,/assets/img/post3/shashank-original-800.webp 800w,/assets/img/post3/shashank-original-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-original.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure slot="second"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-ghibli-openai-480.webp 480w,/assets/img/post3/shashank-ghibli-openai-800.webp 800w,/assets/img/post3/shashank-ghibli-openai-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-ghibli-openai.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </img-comparison-slider> <div class="caption-overlay">OpenAI GPT-4o Ghibli Style</div> </div> </div> <div class="col-md-4"> <div style="position: relative;"> <img-comparison-slider hover="hover" value="70"> <figure slot="first"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-original-480.webp 480w,/assets/img/post3/shashank-original-800.webp 800w,/assets/img/post3/shashank-original-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-original.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure slot="second"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-ghibli-grok-480.webp 480w,/assets/img/post3/shashank-ghibli-grok-800.webp 800w,/assets/img/post3/shashank-ghibli-grok-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-ghibli-grok.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </img-comparison-slider> <div class="caption-overlay">Grok 3 Ghibli Style</div> </div> </div> <div class="col-md-4"> <div style="position: relative;"> <img-comparison-slider hover="hover" value="70"> <figure slot="first"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-original-480.webp 480w,/assets/img/post3/shashank-original-800.webp 800w,/assets/img/post3/shashank-original-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-original.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure slot="second"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-ghibli-gemini-480.webp 480w,/assets/img/post3/shashank-ghibli-gemini-800.webp 800w,/assets/img/post3/shashank-ghibli-gemini-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-ghibli-gemini.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </img-comparison-slider> <div class="caption-overlay">Google Gemini Ghibli Style</div> </div> </div> </div> </div> <p><br/></p> <p><strong>Are the results worth the hype?</strong></p> <p>I compare the quality of the various multimodal models such as OpenAI‚Äôs <code class="language-plaintext highlighter-rouge">GPT-4o</code>, XAI‚Äôs <code class="language-plaintext highlighter-rouge">Grok 3</code>, and Google‚Äôs <code class="language-plaintext highlighter-rouge">Gemini 2.0 Pro Experimental</code> by testing them on the same input image and prompt. Following up on the Studio Ghibli trend, the prompt was ‚ÄúCreate image - convert this to Studio Ghibli style‚Äù. The final image generated by each model is shown here for comparison. We can see that both <code class="language-plaintext highlighter-rouge">GPT-4o</code> and <code class="language-plaintext highlighter-rouge">Grok 3</code> generate pretty reasonable and visually appealing results. The Gemini model, on the other hand, does not capture the intent of the prompt as well as the other two models. When running further tests on images with more people, <code class="language-plaintext highlighter-rouge">GPT-4o</code> edges out <code class="language-plaintext highlighter-rouge">Grok 3</code> in a bunch of cases, but both these models are roughly on par with each other.</p> <p><code class="language-plaintext highlighter-rouge">GPT-4o</code> is also great at generating images in the style of other artists, animation studios, and art movements. For instance, it is capable of generating art in the form of Ukiyo-e, Art Deco, Pixar, Minecraft, Ufotable, and more. It is also capable of arbitrarily changing the background or context of an image, as shown in the comparison slider on the bottom right. In this example, I have a ‚Äúghiblified‚Äù image of myself and a group of friends in Crater Lake, and asked the model to change the background to Sequoia National Park by giving it the following prompt: ‚ÄúCreate image - convert this to Studio Ghibli but replace the background with Sequoia National Park‚Äù. The prompts for changing backgrounds doesn‚Äôt work well when operating on the original image directly. Modifying the prompt slighly to ‚ÄúCreate image - replace the background with Sequoia National Park‚Äù results in a spectacular failure. These models are only going to get better with time, and it does raise some concerns about what is real and what is not. But matter of fact is that this technology is here to stay, and there is no choice but to adapt to it.</p> <p><em>The failure output isn‚Äôt shown here, out of respect for my friends‚Äô privacy.</em></p> <div class="container"> <div class="row"> <div class="col-md-5"> <div class="col-12"> <swiper-container keyboard="true" navigation="true" pagination="true" pagination-clickable="true" pagination-dynamic-bullets="true" rewind="true"> <swiper-slide> <div class="position-relative"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-ufotable-openai-480.webp 480w,/assets/img/post3/shashank-ufotable-openai-800.webp 800w,/assets/img/post3/shashank-ufotable-openai-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-ufotable-openai.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption-overlay">Ufotable Style Portrait</div> </div> </swiper-slide> <swiper-slide> <div class="position-relative"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-starry-night-openai-480.webp 480w,/assets/img/post3/shashank-starry-night-openai-800.webp 800w,/assets/img/post3/shashank-starry-night-openai-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-starry-night-openai.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption-overlay">Starry Night Style</div> </div> </swiper-slide> <swiper-slide> <div class="position-relative"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-minecraft-openai-480.webp 480w,/assets/img/post3/shashank-minecraft-openai-800.webp 800w,/assets/img/post3/shashank-minecraft-openai-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-minecraft-openai.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption-overlay">Minecraft Style</div> </div> </swiper-slide> </swiper-container> </div> </div> <div class="col-md-3"> <swiper-container keyboard="true" navigation="true" pagination="true" pagination-clickable="true" rewind="true" style="height: 100%;"> <swiper-slide> <div class="position-relative"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-manga-openai-480.webp 480w,/assets/img/post3/shashank-manga-openai-800.webp 800w,/assets/img/post3/shashank-manga-openai-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-manga-openai.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption-overlay">Manga Style</div> </div> </swiper-slide> <swiper-slide> <div class="position-relative"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-art-deco-openai-480.webp 480w,/assets/img/post3/shashank-art-deco-openai-800.webp 800w,/assets/img/post3/shashank-art-deco-openai-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-art-deco-openai.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption-overlay">Art Deco Style</div> </div> </swiper-slide> <swiper-slide> <div class="position-relative"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-ukiyo-e-openai-480.webp 480w,/assets/img/post3/shashank-ukiyo-e-openai-800.webp 800w,/assets/img/post3/shashank-ukiyo-e-openai-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-ukiyo-e-openai.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption-overlay">Ukiyo-e Style</div> </div> </swiper-slide> <swiper-slide> <div class="position-relative"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/shashank-pixar-openai-480.webp 480w,/assets/img/post3/shashank-pixar-openai-800.webp 800w,/assets/img/post3/shashank-pixar-openai-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/shashank-pixar-openai.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption-overlay">Pixar Style</div> </div> </swiper-slide> </swiper-container> </div> <div class="col-md-4"> <div style="position: relative;"> <img-comparison-slider hover="hover" value="70"> <figure slot="first"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/crater-lake-480.webp 480w,/assets/img/post3/crater-lake-800.webp 800w,/assets/img/post3/crater-lake-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/crater-lake.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure slot="second"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/sequoia-480.webp 480w,/assets/img/post3/sequoia-800.webp 800w,/assets/img/post3/sequoia-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/sequoia.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </img-comparison-slider> <div class="caption-overlay">Background Replacement</div> </div> </div> </div> </div> <p><br/></p> <style>.position-relative{position:relative;width:100%}.caption-overlay{position:absolute;bottom:0;left:0;right:0;background-color:rgba(0,0,0,0.7);color:white;padding:8px 15px;text-align:center;border-bottom-left-radius:4px;border-bottom-right-radius:4px}</style> <h4 id="is-it-a-fad-or-a-big-deal">Is it a fad or a big deal?</h4> <p>The Studio Ghibli trend went viral on social media, and it was akin to the original ChatGPT moment, albeit on a much smaller scale. Just like any viral trend on social media, this too will eventually fade away. However, unlike other highly hyped trends in the Generative AI space, such as video generation models like <a href="https://pika.art/login">Pika AI</a>, Autonomous agents like <a href="https://devin.ai/">Devin AI</a>, <a href="https://manus.im/">Manus</a> etc., this trend seems to be more secular. According to Sam Altman, Native image generation has already resulted in OpenAI gaining over <code class="language-plaintext highlighter-rouge">1</code> million users in an <a href="https://x.com/sama/status/1906771292390666325">hour</a> and <a href="https://x.com/sama/status/1905296867145154688">overloaded their servers</a> resulting in them imposing temporary rate limits on free as well as paid users.</p> <h3 id="real-world-use-cases-of-this-technology">Real world use-cases of this technology</h3> <p>Right now, the biggest use case for these models seems to be simply generating cute/fun images in different styles. And even this simple use case will result in the release of new consumer-facing applications and tools. However, this technology also opens up several other interesting possibilities, especially in the virtual and augmented reality space, as well as in the realm of user interfaces.</p> <h4 id="generative-reality"><strong>Generative Reality</strong></h4> <p>As the ability of these models improve over time, and the latency of generating these images improves, there is a future where these models can be used to generate images in real-time, and even alter the notion of reality around us. This is what I call ‚ÄúGenerative Reality‚Äù, a new made-up term. The term ‚ÄúGenerative Reality‚Äù (<code class="language-plaintext highlighter-rouge">GR</code>) hasn‚Äôt been widely explored in academic literature, but it has appeared in various forms throughout science fiction shows like <a href="https://www.imdb.com/title/tt11680642/">Pantheon</a> (must watch for science fiction fans), and books like <a href="https://en.wikipedia.org/wiki/Ready_Player_One">Ready Player One</a>, and <a href="https://en.wikipedia.org/wiki/Snow_Crash">Snow Crash</a>. Most of these books/shows, however, focus on the concept of Virtual Reality (VR) and ‚ÄúGenerative Reality‚Äù is slightly different. Unlike Augmented Reality which overlays information on top of the real world, <code class="language-plaintext highlighter-rouge">GR</code> alters the way we perceive the world by generating new images in real-time via style transfer while keeping the generated images grounded in reality. For example, a Apple Vision Pro like headset can potentially replace the ‚Äúreal world‚Äù with a Studio Ghibli style world, as shown below. The existence of native image generation models like <code class="language-plaintext highlighter-rouge">GPT-4o</code> and <code class="language-plaintext highlighter-rouge">Grok 3</code> make this a real possibility at some point in the future.</p> <div class="row justify-content-center w-100"> <div class="col-md-6"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/generative-reality-ghibli-480.webp 480w,/assets/img/post3/generative-reality-ghibli-800.webp 800w,/assets/img/post3/generative-reality-ghibli-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/generative-reality-ghibli.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="figure-caption text-center mt-2"> Generative Reality - Replacing the real world with a Studio Ghibli style world </figcaption> </div> <div class="col-md-6"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/generative-reality-daylight-savings-480.webp 480w,/assets/img/post3/generative-reality-daylight-savings-800.webp 800w,/assets/img/post3/generative-reality-daylight-savings-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/generative-reality-daylight-savings.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figcaption class="figure-caption text-center mt-2"> Generative Reality - Replacing the real world with a Studio Ghibli style world </figcaption> </div> </div> <p><br/></p> <p>This <a href="https://www.bbc.com/news/world-europe-50571010">article</a> goes over a more dystopian example of using VR headsets to show a ‚Äúunique summer field simulation program‚Äù to Dairy cows to improve yields. A slightly less dystopian (still dystopian) example is to use <code class="language-plaintext highlighter-rouge">GR</code> to ‚Äúsolve‚Äù the Daylight Savings Time problem.</p> <h5 id="dystopian-nightmare-a-solution-to-switching-the-clocks">Dystopian Nightmare: A solution to switching the clocks</h5> <p>The debate around Universal standard time and Daylight Savings Time resurfaces during the first week of November and March every year, when the clocks are set back or forward. Proponents of Universal Time argue it aligns with natural circadian rhythms, while Daylight Savings advocates favor extended evening daylight for leisure. Here‚Äôs a tongue-in-cheek (and dystopian) idea: instead of changing clocks, Generative Reality could adjust how the world looks based on personal preference. Prefer Daylight Savings? Your headset could render the world as if it‚Äôs an hour ahead.</p> <h4 id="generative-ui"><strong>Generative UI</strong></h4> <p>A much more practical use case for native image generation is <a href="https://uxdesign.cc/an-introduction-to-generative-uis-01dcf6bca808">‚ÄúGenerative UI‚Äù</a> ‚Äî using generative models to create adaptive, context-aware user interfaces.</p> <p>Generative UI can be used to create personalized user interfaces that adapt to the user‚Äôs needs and preferences in real-time. For example, if a user is booking a business trip via Airbnb, the generative UI can automatically adjust the layout, to focus more on commute time to the downtown, or the speed of Wi-Fi at the hotel. On the other hand, family vacation booking might look more like existing Airbnb interfaces, with greater emphasis on family-friendly amenities, safety features, and cost comparisons as shown below. Unlike ‚ÄúGenerative Reality‚Äù, this is not a pipe dream, and is already supported to a certain extent by tools like Vercel‚Äôs <a href="https://sdk.vercel.ai/docs/ai-sdk-ui/generative-user-interfaces">AI SDK</a>.</p> <div class="container"> <div class="row justify-content-center"> <div class="col-md-10"> <div style="position: relative;"> <img-comparison-slider hover="hover" value="60"> <figure slot="first"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/airbnb-family-480.webp 480w,/assets/img/post3/airbnb-family-800.webp 800w,/assets/img/post3/airbnb-family-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/airbnb-family.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure slot="second"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post3/airbnb-business-480.webp 480w,/assets/img/post3/airbnb-business-800.webp 800w,/assets/img/post3/airbnb-business-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post3/airbnb-business.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </img-comparison-slider> <div class="caption-overlay">Generative UI for two different usecases: Family Travel &amp; Business Travel.</div> </div> </div> </div> </div> <p><br/></p> <h3 id="whats-next"><strong>What‚Äôs Next?</strong></h3> <p>In terms of immediate industry headwinds, companies like Adobe, Figma, and stock photo platforms like Shutterstock and Unsplash are likely to be affected the most by the rise of native image generation models.</p> <ul> <li> <p><strong>Adobe and Figma</strong> are obviously affected the most, as their tools are heavily used for graphic design, UI/UX design, mockups, and image editing. Even if the current models cannot fully replace the need for professional design tools completely, they will only get better at instruction following over time, and will replace the need for these tools amongst the more casual users and hobbyists.</p> </li> <li> <p>The other companies that face significant negative headwinds are stock photo hosting and sharing platforms like <strong>Shutterstock and Unsplash</strong>. As image generation keeps improving, the need for licensing stock photos will continue to diminish, and the role of these companies will be ‚Äúdiminished‚Äù to that of licensing images for training these models. However, the timeline of this happening is not clear, since other Image generation models like Midjourney and Stable Diffusion have been around for a while, and have not significantly disrupted this market yet.</p> </li> <li> <p>There‚Äôs also potentially positive headwinds for <strong>AR/VR</strong> companies like Meta, Apple, Samsung, and more, since these models can help with creating newer User interfaces that are likely to make the AR/VR experience more immersive and personalized.</p> </li> <li> <p><strong>Social media companies</strong> like Meta, Snapchat, and TikTok could also integrate these tools into their platforms to allow users to add more interactive filters to their stories and posts, increasing user engagement and retention.</p> </li> </ul> <h4 id="world-modeling-using-3d-data-and-video">World Modeling using 3D Data and Video</h4> <p>As far as the core LLM technology is concerned, the logical next step would be to train these multi-modal models on even larger datasets, and even more modalities like video, and 3D models. Companies like <a href="https://worldlabs.ai/blog">World Labs</a> are already working on 3D world generation using LLMs / Foundation Models, and future frontier models like <code class="language-plaintext highlighter-rouge">Gemini-3.0</code>, <code class="language-plaintext highlighter-rouge">Grok 4</code>, <code class="language-plaintext highlighter-rouge">GPT-6</code> and more will likely have support for autoregressive video and 3D world generation as well. The priors for this happening are quite high, due to the existence of several large datasets of videos and 3D models available on the internet:</p> <ul> <li><strong>Video datasets</strong>: All the content in YouTube, TikTok, movies, and more</li> <li><strong>3D datasets</strong>: Data from varioues sources like Lidar scans from autonomous vehicles, 3D assets in game engines like Unreal Engine, Unity, and Blender, and spatial reconstruction data from NeRFs (Neural Radiance Fields) deployed in smartphone cameras and other devices.</li> </ul>]]></content><author><name></name></author><category term="tech"/><category term="llms"/><category term="ar"/><category term="openai"/><summary type="html"><![CDATA[Generative Reality - The next step in native image generation]]></summary></entry><entry><title type="html">Putting 2025 in Perspective - State of the Tech/LLM Industry</title><link href="https://talsperre.github.io/blog/2025/new-year/" rel="alternate" type="text/html" title="Putting 2025 in Perspective - State of the Tech/LLM Industry"/><published>2025-01-02T09:00:00+00:00</published><updated>2025-01-02T09:00:00+00:00</updated><id>https://talsperre.github.io/blog/2025/new-year</id><content type="html" xml:base="https://talsperre.github.io/blog/2025/new-year/"><![CDATA[<p>It‚Äôs 2025 now, so happy new year everyone! üéâ. This blog post arrives a few days later than it‚Äôs supposed to, because, guess what, I am a master procrastinator. But hey, better late than never, right? üòÖ This is going to be the first of many posts that I aim to write as part of my personal blog called ‚ÄúEssential Matrix‚Äù. I will primarily focus on writing about the Tech or Tech adjacent industry, with random musings and ramblings interspersed in between.</p> <p>Anyways, enough about my blog, and back to the main theme of this post - A short look back into 2024, cool facts about the year 2025 special, and putting 2025 in perspective with respect to historical events of note. Starting with some random facts:</p> <ul> <li><code class="language-plaintext highlighter-rouge">2025</code> is a perfect square, as it can be expressed as \(45^2\). For most people born in the late 20th or early 21st century, this will most likely be the only perfect square year they will witness in their lifetime. Unless, you are <a href="https://time.com/6315607/bryan-johnsons-quest-for-immortality/">Bryan Johnson</a>, or there is a major breakthrough in longevity research. The next perfect square year will be \(46^2 = 2116\), which is \(91\) years away. The difference between any two perfect square years is continuously increasing, and can be expressed as \(2n + 1\), where \(n\) is the perfect square root of the year. Here‚Äôs some quick maths for it:</li> </ul> \[\begin{align*} (n+1)^2 - n^2 &amp;= ((n+1) + n)((n+1) - n) \\ &amp;= (2n + 1)(1) \\ &amp;= 2n + 1 \\ &amp;\text{Since } a^2 - b^2 = (a + b)(a - b), \text{ where } a = (n+1) \text{ and } b = n. \end{align*}\] <ul> <li>Continuing with more maths:</li> </ul> \[\begin{align*} 2025 &amp;= (20 + 25)^2 \\ &amp;= 1^3 + 2^3 + 3^3 + 4^3 + 5^3 + 6^3 + 7^3 + 8^3 + 9^3 \\ &amp;= 9 + 9 + 9 + 999 + 999 \\ \end{align*}\] <ul> <li><code class="language-plaintext highlighter-rouge">2025</code> also heralds the beginning of a new generation: <a href="https://www.businessinsider.com/gen-alpha-no-longer-youngest-generation-gen-beta-has-arrived-2025-1">Generation Beta</a>. Definitely, not the best name for a generation, given the negative connotations, but let‚Äôs not digress into that.</li> </ul> <h3 id="things-that-remained-the-same-in-2024">Things that remained the same in 2024</h3> <ul> <li>For starters, One Piece is still running; Winds of Winter is still not out; and GTA 6 is yet to be released. George R. R. Martin is the most prolific procrastinator of them all üòÖ.</li> <li>Adding to the list of things that didn‚Äôt happen: <ul> <li>Flying cars are still not a thing, and Peter Thiel‚Äôs <a href="https://tnmt.com/newsletter-snippets/they-promised-us-flying-cars/">quote</a> about ‚ÄúWe wanted flying cars, instead we got 140 characters‚Äù still holds true.</li> <li>Nuclear fusion is still only a decade away from solving all of humanity‚Äôs energy problems. The first test for ITER is supposedly in <a href="https://www.livescience.com/physics-mathematics/worlds-largest-nuclear-reactor-is-finally-completed-but-it-wont-run-for-another-15-years">2039</a>.</li> <li>Quantum computing is also still not a thing - although <a href="https://blog.google/technology/research/google-willow-quantum-chip/">Google‚Äôs Willow</a> announcement did demonstrate significant breakthroughs in the field.</li> </ul> </li> <li>Sutton‚Äôs bitter lesson still continues to hold true, and the frontier models continue to improve significantly. Claude Sonnet 3.5 (New), aka Sonnet 3.6, is a major part of my daily workflow. Competition in this space is heating up, with new models constantly dethroning the previous ones in <a href="https://lmarena.ai/">LM Arena</a>. Personally, I am most excited by the Deepseek V3 <a href="https://techcrunch.com/2024/12/26/deepseeks-new-ai-model-appears-to-be-one-of-the-best-open-challengers-yet/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAA7gdeeXoLhVq6eKujg65469N-Ep5I6Ul85jxeQneLRvQYJ30ivnje6AA0spHhCkSrfWmL3vn1iTwk-_If0xRPQyDL0lSMxB2cfbRhm8VPaSERmB1EB8qvF600GeXyRCyuAU27bxTmX-oY8IqsVbpcSxYfEZe09bacS8S3slhvnc">announcement</a>, and can‚Äôt wait to try their 671 Billion parameter model out.</li> </ul> <div class="row justify-content-center"> <div class="col-10"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post1/gpus_go_brrr.webp" sizes="95vw"/> <img src="/assets/img/post1/gpus_go_brrr.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <ul> <li>LLM providers working on frontier models continue to be really bad at <a href="https://x.com/nearcyan/status/1866939351592210573">naming</a> their models. The names of the models just don‚Äôt make any sense: It just makes more sense to rename ‚ÄúClaude Sonnet 3.5 (New)‚Äù to ‚ÄúClaude Sonnet 3.6‚Äù and ‚ÄúGemini 2.0 Flash Thinking‚Äù to something simpler like ‚ÄúGemini Reasoning 1. 0‚Äù. OpenAI‚Äôs ‚Äúo1‚Äù and ‚Äúo3‚Äù naming conventions are confusing as well - is ‚ÄúGPT 4o‚Äù supposed to be the ‚Äúbetter‚Äù model or ‚ÄúGPT o1‚Äù. Someone not in tune with the latest developments in the field would be completely lost.</li> </ul> <div class="row justify-content-center"> <div class="col-4"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post1/openai-480.webp 480w,/assets/img/post1/openai-800.webp 800w,/assets/img/post1/openai-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post1/openai.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-4"> <div class="row mb-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post1/google-480.webp 480w,/assets/img/post1/google-800.webp 800w,/assets/img/post1/google-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post1/google.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="row mb-3"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post1/anthropic-480.webp 480w,/assets/img/post1/anthropic-800.webp 800w,/assets/img/post1/anthropic-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post1/anthropic.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> </div> <h3 id="things-that-i-didnt-expect-in-2024">Things that I didn‚Äôt expect in 2024</h3> <ul> <li>Apple finally announced <a href="https://www.theverge.com/2024/11/7/24290703/apple-green-bubble-message-reaction-rcs-android">support</a> for RCS, and enabled it from iOS 18.1 onwards.</li> <li>Continuing on the Apple theme, they also finally released an iPhone with a USB-C port, and upgraded the base <a href="https://9to5mac.com/2024/11/01/macbook-air-ram-upgrade-announcement/">memory</a> in their Mac lineup to 16GB.</li> <li>Python <code class="language-plaintext highlighter-rouge">3.13</code> was finally <a href="https://www.python.org/downloads/release/python-3130/">released</a>, and it makes the Global Interpreter Lock (GIL) optional. <ul> <li>For anyone unaware about the story of GIL and Python, it‚Äôs simply a mutex that protects access to Python objects, and allows only one thread to hold the control of the Python interpreter. This makes scaling true multi-threaded Python applications is hard.</li> <li>This <a href="https://peps.python.org/pep-0703/">PEP</a> describes the issue in detail, and honestly, does a way better job explaining it than I ever could.</li> </ul> </li> <li>The scaling laws for LLMs don‚Äôt seem to be holding as well as expected, and a lot of research focus is towards scaling test time compute for models like OpenAI‚Äôs o1, o3, and Deepmind‚Äôs Gemini 2.0 Flash Thinking.</li> </ul> <h3 id="what-the-future-beholds">What the future beholds</h3> <div style="border: 1px solid #ccc; padding: 10px; margin: 10px 0; background-color: #f0f8ff; font-family: Libre Baskerville, serif; font-style: italic; font-size: 1.1em;"> The release of the first iPhone on June 29, 2007 is equally close chronologically to the fall of the Berlin Wall on November 9, 1989, than it is to today's date. </div> <p>The world changes quickly, and it seems like the pace of change is only increasing with time. To put things into perspective, in 1989, the Internet as we know today was not a thing, there were no smartphones, and most of the biggest tech companies of today like Google, Amazon, Facebook, and Netflix, were not even founded. Software had not yet eaten the world, and this was clearly visible when looking at a plot of the top 5 companies by market cap in 1989:</p> <div class="l-page"> <iframe src="/assets/d3/post1/market_cap_1989.html" width="100%" height="500px" style="border: 1px dashed grey; overflow: hidden;"> </iframe> </div> <p>There‚Äôs only one American company in the top 5, and the rest all were Japanese. The dominant industries were Banking, Energy, and Automobiles, and the Tech industry was still in its nascent stages. The only American tech company in the top 10 was IBM. Industrial Bank of Japan was the most valuable with a market cap of $104.3 Billion dollars, but that dwarfs in comparison to Apple‚Äôs <a href="https://www.wsj.com/market-data/quotes/AAPL/financials/annual/income-statement">gross income</a> of roughly $180 Billion in 2024. The dramatic shift in the markets is best understood by looking at the same plot as of 2024:</p> <div class="l-page"> <iframe src="/assets/d3/post1/market_cap_2024.html" width="100%" height="500px" style="border: 1px dashed grey; overflow: hidden;"> </iframe> </div> <p>In 2025, the top 5 companies by market cap are all tech companies, and three out of the top five were founded after 1989. All the top five companies are American, and only one Japanese company still remains in the top 50 - Toyota. Tech industry is absolutely dominant, and the dominance of the American Big Tech companies is staggering - only four companies in the top 20 are not American - Saudi Aramco, TSMC, Eli Lilly, and Tencent. A lot of this dominance of American big tech companies can be attributed to the zero marginal cost of software, and the network and aggregation effects that accumulate over time. However, this zero marginal cost of software might not continue to hold in the future, especially with the rise of LLMs and new reasoning models like o1, o3, and Gemini 2.0 Flash Thinking that use compute during test/inference time as well. If we are to believe Sam Altman, the ChatGPT Pro subscription which costs $200 per month, is still continuing to <a href="https://techcrunch.com/2025/01/05/openai-is-losing-money-on-its-pricey-chatgpt-pro-plan-ceo-sam-altman-says/">lose money</a> for OpenAI.</p> <h4 id="how-it-all-ties-back-to-the-present-and-the-near-future">How it all ties back to the present and the near future</h4> <p>The reason I bring up the launch of the iPhone as a reference point is that it would have been possible for someone in 2007 to predict the dominance of the tech giants in 2025, even if no one could have predicted the exact set of companies that would dominate. In fact, an astute observer might have predicted that companies like Google, Amazon, Facebook, and Apple would be the top companies by market cap in 2025, and they would have been right mostly.</p> <p>The public release of the first transformer model in 2017 via the ‚ÄúAttention is all you need‚Äù paper, is most likely a similar seminal moment in the tech industry. 2017 was only eight years ago, but we can already see the ripple effects of the transformer model in the tech industry. Nvidia‚Äôs market cap in 2015 was roughly $17 Billion, and it was not even in the <a href="https://www.pwc.com/gx/en/audit-services/capital-market/publications/assets/document/pwc-global-top-100-march-update.pdf">top 100</a> companies by market cap. Now, in 2025, Nvidia is the second/third most valuable company in the world, depending on the day. A good question to ask is whether someone in 2025 can make reasonable predictions about the top companies by market cap in 2033, exactly eight years from now. For posterity‚Äôs sake, here are my predictions:</p> <ol> <li><code class="language-plaintext highlighter-rouge">Nvidia</code> - no surprises here, Nvidia‚Äôs GPUs are fundamental to all parts of the LLM ecosystem, and it‚Äôs hard to see them lose ground in the training/inference compute market given their CUDA ecosystem and moat.</li> <li><code class="language-plaintext highlighter-rouge">Google</code> - another no-brainer, given Google‚Äôs dominance in the search market, their incredible AI research team, access to vast amounts of compute and specialized hardware like TPUs, and access to sources of data that no other company has, like YouTube videos, Search history, and Maps/Navigational data. A lot of benefits of foundation models will also accrue to the aggregators and Google would be the biggest beneficiary given their ownership of Google Search, Android, Chrome, and YouTube.</li> <li><code class="language-plaintext highlighter-rouge">Apple</code> - while Apple is not in the forefront of the AI/LLM space, they will still be one of the biggest beneficiaries of the rise of LLMs simply due to their ownership of the App Store, and iOS ecosystem. Any time someone subscribes to a ChatGPT Pro, or Google‚Äôs new Gemini models, Apple gets a cut of the subscription revenue. Additionally, Apple can always use the frontier models from OpenAI, Google to distill knowledge and train their own smaller models for on-device inference, and off-load any heavy lifting to these LLM providers. Thus, Apple‚Äôs current AI strategy seems to make a lot of sense financially speaking, with the big risk being that LLMs may fundamentally change the way software is written and consumed, leaving Apple behind, just like Blackberry was left behind when the iPhone was launched.</li> <li><code class="language-plaintext highlighter-rouge">Microsoft</code>/<code class="language-plaintext highlighter-rouge">OpenAI</code> - again, not much needs to be said here. OpenAI has continuously been at the forefront of pushing frontier models, and Microsoft just like Google, Meta, and Apple, will be a big beneficiary of the rise of LLMs due to their position as an aggregator. Microsoft is fully committed to investing in this space, and aims to invest over $80 Billion dollars on building data centers. This number is mind-boggling, but makes sense if you consider that Microsoft does not want to miss on the next computing paradigm shift, given their abysmal record in the mobile domain.</li> <li><code class="language-plaintext highlighter-rouge">Meta</code> - they have a great research team, and also have access to vast amounts of data from Facebook, Instagram, and WhatsApp, which is simply not available to any other company. Additionally, as an aggregator, they benefit from the network effects of the platform, and the dominance of Generative AI models for image and video generation would be hugely beneficial for their advertising business.</li> </ol> <p>Other than these five companies, the other notable runners-up would be <code class="language-plaintext highlighter-rouge">Amazon</code> (AWS duh), <code class="language-plaintext highlighter-rouge">SpaceX</code> (if they go public), <code class="language-plaintext highlighter-rouge">Eli Lilly</code> (Mounjaro and other GLP-1 inhibitors are doing really well). The interesting thing to note about my predictions, which can obviously be wrong, is that it assumes that no new competitors will emerge in the next eight years. There are two main reasons for my predictions:</p> <ul> <li>While the zero marginal cost of software allowed several companies to emerge and dominate the tech industry, and leapfrog the incumbents, the LLM/AI paradigm shift is fundamentally different. As Doug O‚ÄôLaughlin put recently in his <a href="https://www.fabricatedknowledge.com/p/2025-ai-and-semiconductor-outlook">blog post</a> marginal costs are coming for tech companies, and the death of ZIRP (Zero Interest Rate Phenomenon) means that the incumbents are the most well-equipped to handle the rising costs of compute.</li> <li>Additionally, the emergence of newer models like Deepseek V3, seems to indicate that frontier LLMs might soon be a commodity, and the real value would be in the data and the underlying network effects of the platform. This is where the aggregators like Google, Meta, Apple, and Microsoft have the biggest moat, and it‚Äôs hard to see any new entrant breaking into these respective moats/de-facto monopolies.</li> </ul> <p>One major source of risk that these predictions do not account for is all sorts of regulatory risks that these companies face, especially in the antitrust domain. However, barring any major regulatory changes, or AT&amp;T style breakups, this should not have a major impact on the dominance of these companies.</p> <h3 id="zooming-out">Zooming out</h3> <p>While making predictions about the future is fun, it‚Äôs important to zoom out and realize that the future is inherently unpredictable. <a href="https://en.wikipedia.org/wiki/Roy_Amara">Roy Amara</a>, famously stated the following quote, also known as Amara‚Äôs Law:</p> <blockquote><p>We tend to overestimate the effect of a technology in the short run and<br/>underestimate the effect in the long run.</p><cite><a class="citation" href="#"></a></cite></blockquote> <p>In essence, even if the progress in the next eight years is not as revolutionary as the last eight years (which is highly unlikely), the cumulative effect of the progress in various domains will continue to compound, and the future will be vastly different from what we can imagine today. For instance, the year 2025 is closer to the year 2100 than it is to the year 1950. The illustration below shows some of the major technological breakthroughs that happen in the last 75 years, primarily in the bits and atoms domain.</p> <div class="row justify-content-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/post1/visualization_75_years1-480.webp 480w,/assets/img/post1/visualization_75_years1-800.webp 800w,/assets/img/post1/visualization_75_years1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/post1/visualization_75_years1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Specifically, humanity mastered quantum mechanics, resulting in the development of the Tsar Bomba, the most powerful nuclear weapon ever detonated. Humans also designed the first transistor, landed on the moon, and developed the internet in this time frame. And finally, the other big breakthrough was the launch of the iPhone, which fundamentally changed the way most people interact with technology. The next 75 years are likely to have just as many, if not more, breakthroughs: mastering fusion, figuring out quantum computing, colonizing Mars, developing AGI, and maybe even curing cancer and aging.</p> <p>That‚Äôs all for this post - see you in the next one! üöÄ</p>]]></content><author><name></name></author><category term="random-musings"/><category term="llm"/><category term="tech-news"/><category term="random"/><category term="llm"/><category term="tech"/><summary type="html"><![CDATA[A post looking back at 2024, evaluating the state of the Tech/LLM industry in 2025, with a nod to historical events of note.]]></summary></entry><entry><title type="html">Introducing Configurable Metaflow | by Netflix Technology Blog | Netflix TechBlog</title><link href="https://talsperre.github.io/blog/2024/introducing-configurable-metaflow-by-netflix-technology-blog-netflix-techblog/" rel="alternate" type="text/html" title="Introducing Configurable Metaflow | by Netflix Technology Blog | Netflix TechBlog"/><published>2024-12-19T00:00:00+00:00</published><updated>2024-12-19T00:00:00+00:00</updated><id>https://talsperre.github.io/blog/2024/introducing-configurable-metaflow--by-netflix-technology-blog--netflix-techblog</id><content type="html" xml:base="https://talsperre.github.io/blog/2024/introducing-configurable-metaflow-by-netflix-technology-blog-netflix-techblog/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[David J. Berg*, David Casler^, Romain Cledat*, Qian Huang*, Rui Lin*, Nissan Pow*, Nurcan Sonmez*, Shashank Srikanth*, Chaoying Wang*, Regina Wang*, Darin Yu* *: Model Development Team, Machine‚Ä¶]]></summary></entry><entry><title type="html">Supporting Diverse ML Systems : Netflix Tech Blog | Netflix TechBlog</title><link href="https://talsperre.github.io/blog/2024/supporting-diverse-ml-systems-netflix-tech-blog-netflix-techblog/" rel="alternate" type="text/html" title="Supporting Diverse ML Systems : Netflix Tech Blog | Netflix TechBlog"/><published>2024-03-07T00:00:00+00:00</published><updated>2024-03-07T00:00:00+00:00</updated><id>https://talsperre.github.io/blog/2024/supporting-diverse-ml-systems--netflix-tech-blog--netflix-techblog</id><content type="html" xml:base="https://talsperre.github.io/blog/2024/supporting-diverse-ml-systems-netflix-tech-blog-netflix-techblog/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Machine Learning Platform at Netflix provides an entire ecosystem of integrations for practitioners so they can tackle a diverse set of business problems.]]></summary></entry></feed>